{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8de1af17-82e2-4792-8da5-053aaf33a810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40114641-a771-429d-9e88-fd7d72d7f1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = jnp.array([1.,2.,3.])\n",
    "a_gpu = jax.device_put(a, device=jax.devices('gpu')[0]) # explicit transfer\n",
    "pwr = jax.device_put(2., jax.devices('gpu')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81be47bc-78d6-42ea-a8ea-d1a1bc7c687a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return (x**y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44e3225b-bcd9-466f-a3ec-a31328186197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_jit = jax.jit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e47c845f-d953-497a-8e9a-9abbde328c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with jax.transfer_guard('disallow'):\n",
    "    _ = f(a_gpu, pwr)\n",
    "    _ = f_jit(a_gpu, pwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa1b9572-17fb-41f6-93e3-98f5e8d11a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "XlaRuntimeError",
     "evalue": "INVALID_ARGUMENT: Disallowed host-to-device transfer: aval=ShapedArray(float32[]), dst_sharding=GSPMDSharding({replicated})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtransfer_guard(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisallow\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     _, _ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(f_jit)(a_gpu, pwr)\n",
      "    \u001b[0;31m[... skipping hidden 24 frame]\u001b[0m\n",
      "File \u001b[0;32m/pscratch/sd/i/imendoza/miniconda3/envs/bpd_gpu2/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:192\u001b[0m, in \u001b[0;36mbatched_device_put\u001b[0;34m(aval, sharding, xs, devices, committed)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bufs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(xs):\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m array\u001b[38;5;241m.\u001b[39mArrayImpl(\n\u001b[1;32m    191\u001b[0m       aval, sharding, bufs, committed\u001b[38;5;241m=\u001b[39mcommitted, _skip_checks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatched_device_put\u001b[49m\u001b[43m(\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommitted\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INVALID_ARGUMENT: Disallowed host-to-device transfer: aval=ShapedArray(float32[]), dst_sharding=GSPMDSharding({replicated})"
     ]
    }
   ],
   "source": [
    "with jax.transfer_guard('disallow'):\n",
    "    _, _ = jax.value_and_grad(f)(a_gpu, pwr)\n",
    "    _, _ = jax.value_and_grad(f_jit)(a_gpu, pwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f32564-2560-4015-9848-41affc46cd53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpd_gpu2",
   "language": "python",
   "name": "bpd_gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
